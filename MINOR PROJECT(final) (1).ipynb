{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea0619b-51e4-47ee-90c1-231e9b2f6200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR FIXED OBSTACLE\n",
    "import pygame\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Q-learning parameters\n",
    "GRID_SIZE = 7\n",
    "START = (0, 0)\n",
    "GOAL = (4, 4)\n",
    "OBSTACLE = [(2, 2), (3, 2)]\n",
    "\n",
    "ACTIONS = {\n",
    "    0: (-1, 0),  # Up\n",
    "    1: (1, 0),   # Down\n",
    "    2: (0, -1),  # Left\n",
    "    3: (0, 1)    # Right\n",
    "}\n",
    "NUM_ACTIONS = len(ACTIONS)\n",
    "\n",
    "Q_table = np.zeros((GRID_SIZE, GRID_SIZE, NUM_ACTIONS))\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.1\n",
    "episodes = 500\n",
    "max_steps = 100\n",
    "\n",
    "def is_valid(x, y):\n",
    "    return 0 <= x < GRID_SIZE and 0 <= y < GRID_SIZE and (x, y) not in OBSTACLE\n",
    "\n",
    "# Train Q-table\n",
    "for episode in range(episodes):\n",
    "    x, y = START\n",
    "    steps = 0\n",
    "    while (x, y) != GOAL and steps < max_steps:\n",
    "        steps += 1\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(list(ACTIONS.keys()))\n",
    "        else:\n",
    "            action = np.argmax(Q_table[x, y])\n",
    "        new_x = x + ACTIONS[action][0]\n",
    "        new_y = y + ACTIONS[action][1]\n",
    "        if is_valid(new_x, new_y):\n",
    "            reward = 10 if (new_x, new_y) == GOAL else -1\n",
    "            old_value = Q_table[x, y, action]\n",
    "            next_max = np.max(Q_table[new_x, new_y])\n",
    "            Q_table[x, y, action] = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            x, y = new_x, new_y\n",
    "        else:\n",
    "            reward = -5\n",
    "            Q_table[x, y, action] = (1 - alpha) * Q_table[x, y, action] + alpha * reward\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "# Get optimal path\n",
    "def get_optimal_path():\n",
    "    x, y = START\n",
    "    path = [START]\n",
    "    steps = 0\n",
    "    max_path_steps = GRID_SIZE * 2\n",
    "    while (x, y) != GOAL and steps < max_path_steps:\n",
    "        steps += 1\n",
    "        action = np.argmax(Q_table[x, y])\n",
    "        new_x = x + ACTIONS[action][0]\n",
    "        new_y = y + ACTIONS[action][1]\n",
    "        if not is_valid(new_x, new_y):\n",
    "            break\n",
    "        x, y = new_x, new_y\n",
    "        path.append((x, y))\n",
    "    return path\n",
    "\n",
    "# --- Pygame Visualization ---\n",
    "pygame.init()\n",
    "CELL_SIZE = 100\n",
    "SCREEN_SIZE = GRID_SIZE * CELL_SIZE\n",
    "screen = pygame.display.set_mode((SCREEN_SIZE, SCREEN_SIZE))\n",
    "pygame.display.set_caption(\"Q-Learning Robot Path\")\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "GRAY = (200, 200, 200)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "ORANGE = (255, 165, 0)\n",
    "\n",
    "# Load robot image\n",
    "robot_img = pygame.image.load(\"D:/robo.png\")\n",
    "robot_img = pygame.transform.scale(robot_img, (CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "def draw_grid(path, robot_pos):\n",
    "    screen.fill(WHITE)\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            rect = pygame.Rect(j * CELL_SIZE, i * CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
    "            pygame.draw.rect(screen, GRAY, rect, 1)\n",
    "\n",
    "    for obs in OBSTACLE:\n",
    "        pygame.draw.rect(screen, RED, (obs[1]*CELL_SIZE, obs[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    pygame.draw.rect(screen, GREEN, (START[1]*CELL_SIZE, START[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "    pygame.draw.rect(screen, BLUE, (GOAL[1]*CELL_SIZE, GOAL[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    for (x, y) in path:\n",
    "        pygame.draw.rect(screen, ORANGE, (y*CELL_SIZE, x*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    screen.blit(robot_img, (robot_pos[1]*CELL_SIZE, robot_pos[0]*CELL_SIZE))\n",
    "    pygame.display.update()\n",
    "\n",
    "# Animation loop\n",
    "optimal_path = get_optimal_path()\n",
    "speed = 2\n",
    "max_fps = 10\n",
    "min_fps = 1\n",
    "looping = False\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "running = True\n",
    "frame_index = 0\n",
    "trail = []\n",
    "\n",
    "while running:\n",
    "    clock.tick(speed)\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_UP:\n",
    "                speed = min(max_fps, speed + 1)\n",
    "            elif event.key == pygame.K_DOWN:\n",
    "                speed = max(min_fps, speed - 1)\n",
    "            elif event.key == pygame.K_l:\n",
    "                looping = not looping\n",
    "\n",
    "    if frame_index < len(optimal_path):\n",
    "        pos = optimal_path[frame_index]\n",
    "        trail.append(pos)\n",
    "        draw_grid(trail, pos)\n",
    "        frame_index += 1\n",
    "    elif looping:\n",
    "        frame_index = 0\n",
    "        trail = []\n",
    "    else:\n",
    "        pygame.display.set_caption(f\"Q-Learning Robot Path - Finished (Speed: {speed} FPS)\")\n",
    "\n",
    "    pygame.display.set_caption(f\"Q-Learning Robot Path - Speed: {speed} FPS\")\n",
    "\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa58c501-9085-4731-a4fa-1fe0510ebf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FOR CHANGING OBSTACLE IN EVERY LOOP\n",
    "import pygame\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Q-learning parameters\n",
    "GRID_SIZE = 8\n",
    "START = (0, 0)\n",
    "GOAL = (7,7)\n",
    "\n",
    "# Function to generate dynamic obstacles\n",
    "def generate_obstacles(num=3):\n",
    "    obs = set()\n",
    "    while len(obs) < num:\n",
    "        pos = (random.randint(0, GRID_SIZE - 1), random.randint(0, GRID_SIZE - 1))\n",
    "        if pos != START and pos != GOAL:\n",
    "            obs.add(pos)\n",
    "    return list(obs)\n",
    "\n",
    "OBSTACLE = generate_obstacles()\n",
    "\n",
    "ACTIONS = {\n",
    "    0: (-1, 0),  # Up\n",
    "    1: (1, 0),   # Down\n",
    "    2: (0, -1),  # Left\n",
    "    3: (0, 1)    # Right\n",
    "}\n",
    "NUM_ACTIONS = len(ACTIONS)\n",
    "\n",
    "Q_table = np.zeros((GRID_SIZE, GRID_SIZE, NUM_ACTIONS))\n",
    "alpha = 0.1\n",
    "gamma = 0.9\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.1\n",
    "episodes = 500\n",
    "max_steps = 100\n",
    "\n",
    "def is_valid(x, y):\n",
    "    return 0 <= x < GRID_SIZE and 0 <= y < GRID_SIZE and (x, y) not in OBSTACLE\n",
    "\n",
    "# Train Q-table\n",
    "for episode in range(episodes):\n",
    "    x, y = START\n",
    "    steps = 0\n",
    "    while (x, y) != GOAL and steps < max_steps:\n",
    "        steps += 1\n",
    "        if random.uniform(0, 1) < epsilon:\n",
    "            action = random.choice(list(ACTIONS.keys()))\n",
    "        else:\n",
    "            action = np.argmax(Q_table[x, y])\n",
    "        new_x = x + ACTIONS[action][0]\n",
    "        new_y = y + ACTIONS[action][1]\n",
    "        if is_valid(new_x, new_y):\n",
    "            reward = 10 if (new_x, new_y) == GOAL else -1\n",
    "            old_value = Q_table[x, y, action]\n",
    "            next_max = np.max(Q_table[new_x, new_y])\n",
    "            Q_table[x, y, action] = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)\n",
    "            x, y = new_x, new_y\n",
    "        else:\n",
    "            reward = -5\n",
    "            Q_table[x, y, action] = (1 - alpha) * Q_table[x, y, action] + alpha * reward\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "# Get optimal path\n",
    "def get_optimal_path():\n",
    "    x, y = START\n",
    "    path = [START]\n",
    "    steps = 0\n",
    "    max_path_steps = GRID_SIZE * 2\n",
    "    while (x, y) != GOAL and steps < max_path_steps:\n",
    "        steps += 1\n",
    "        action = np.argmax(Q_table[x, y])\n",
    "        new_x = x + ACTIONS[action][0]\n",
    "        new_y = y + ACTIONS[action][1]\n",
    "        if not is_valid(new_x, new_y):\n",
    "            break\n",
    "        x, y = new_x, new_y\n",
    "        path.append((x, y))\n",
    "    return path\n",
    "\n",
    "# --- Pygame Visualization ---\n",
    "pygame.init()\n",
    "CELL_SIZE = 100\n",
    "SCREEN_SIZE = GRID_SIZE * CELL_SIZE\n",
    "screen = pygame.display.set_mode((SCREEN_SIZE, SCREEN_SIZE))\n",
    "pygame.display.set_caption(\"Q-Learning Robot Path\")\n",
    "\n",
    "# Colors\n",
    "WHITE = (255, 255, 255)\n",
    "GRAY = (200, 200, 200)\n",
    "RED = (255, 0, 0)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (0, 0, 255)\n",
    "ORANGE = (255, 165, 0)\n",
    "\n",
    "# Load robot image\n",
    "robot_img = pygame.image.load(\"D:/robo.png\")\n",
    "robot_img = pygame.transform.scale(robot_img, (CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "def draw_grid(path, robot_pos):\n",
    "    screen.fill(WHITE)\n",
    "    for i in range(GRID_SIZE):\n",
    "        for j in range(GRID_SIZE):\n",
    "            rect = pygame.Rect(j * CELL_SIZE, i * CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
    "            pygame.draw.rect(screen, GRAY, rect, 1)\n",
    "\n",
    "    for obs in OBSTACLE:\n",
    "        pygame.draw.rect(screen, RED, (obs[1]*CELL_SIZE, obs[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    pygame.draw.rect(screen, GREEN, (START[1]*CELL_SIZE, START[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "    pygame.draw.rect(screen, BLUE, (GOAL[1]*CELL_SIZE, GOAL[0]*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    for (x, y) in path:\n",
    "        pygame.draw.rect(screen, ORANGE, (y*CELL_SIZE, x*CELL_SIZE, CELL_SIZE, CELL_SIZE))\n",
    "\n",
    "    screen.blit(robot_img, (robot_pos[1]*CELL_SIZE, robot_pos[0]*CELL_SIZE))\n",
    "    pygame.display.update()\n",
    "\n",
    "# Animation loop\n",
    "optimal_path = get_optimal_path()\n",
    "speed = 2\n",
    "max_fps = 10\n",
    "min_fps = 1\n",
    "looping = False\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "# Timer for obstacle change\n",
    "last_obstacle_change = time.time()\n",
    "obstacle_change_interval = 8 # seconds\n",
    "\n",
    "running = True\n",
    "frame_index = 0\n",
    "trail = []\n",
    "\n",
    "while running:\n",
    "    clock.tick(speed)\n",
    "    current_time = time.time()\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "        if event.type == pygame.KEYDOWN:\n",
    "            if event.key == pygame.K_UP:\n",
    "                speed = min(max_fps, speed + 1)\n",
    "            elif event.key == pygame.K_DOWN:\n",
    "                speed = max(min_fps, speed - 1)\n",
    "            elif event.key == pygame.K_l:\n",
    "                looping = not looping\n",
    "\n",
    "    # Change obstacles every few seconds\n",
    "    if current_time - last_obstacle_change > obstacle_change_interval:\n",
    "        OBSTACLE = generate_obstacles()\n",
    "        optimal_path = get_optimal_path()\n",
    "        frame_index = 0\n",
    "        trail = []\n",
    "        last_obstacle_change = current_time\n",
    "\n",
    "    # Recalculate the optimal path on each frame and avoid obstacles\n",
    "    if frame_index < len(optimal_path):\n",
    "        pos = optimal_path[frame_index]\n",
    "        trail.append(pos)\n",
    "        if not is_valid(pos[0], pos[1]):  # If the robot encounters an obstacle\n",
    "            # Find a new path immediately (it will try to follow the best action in real-time)\n",
    "            optimal_path = get_optimal_path()  # Recalculate the path dynamically\n",
    "            trail = [START]  # Reset the trail\n",
    "            frame_index = 0  # Restart from the beginning\n",
    "        draw_grid(trail, pos)\n",
    "        frame_index += 1\n",
    "    elif looping:\n",
    "        frame_index = 0\n",
    "        trail = []\n",
    "    else:\n",
    "        pygame.display.set_caption(f\"Q-Learning Robot Path - Finished (Speed: {speed} FPS)\")\n",
    "\n",
    "    pygame.display.set_caption(f\"Q-Learning Robot Path - Speed: {speed} FPS\")\n",
    "\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
